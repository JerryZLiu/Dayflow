//
//  ChatCLIProvider.swift
//  Dayflow
//
//  Runs ChatGPT (Codex CLI) or Claude Code in headless mode using
//  sandboxed config files that disable MCP servers. Keeps output
//  JSONâ€‘only via prompt instructions (no CLI json flags required).
//

import Foundation
import AppKit
import AVFoundation

enum ChatCLITool: String, Codable {
    case codex
    case claude
}

private struct ChatCLIConfigManager {
    static let shared = ChatCLIConfigManager()

    let baseDirectory: URL
    let claudeSettingsDirectory: URL
    let claudeSettingsFile: URL
    let codexConfigFile: URL

    private init() {
        let appSupport = FileManager.default.urls(for: .applicationSupportDirectory, in: .userDomainMask).first!
        baseDirectory = appSupport.appendingPathComponent("Dayflow/chatcli", isDirectory: true)
        claudeSettingsDirectory = baseDirectory.appendingPathComponent(".claude", isDirectory: true)
        claudeSettingsFile = claudeSettingsDirectory.appendingPathComponent("settings.local.json")
        codexConfigFile = baseDirectory.appendingPathComponent("config.toml")
    }

    func ensureSandbox() {
        let fm = FileManager.default
        if !fm.fileExists(atPath: baseDirectory.path) {
            try? fm.createDirectory(at: baseDirectory, withIntermediateDirectories: true)
        }
        if !fm.fileExists(atPath: claudeSettingsDirectory.path) {
            try? fm.createDirectory(at: claudeSettingsDirectory, withIntermediateDirectories: true)
        }
        if !fm.fileExists(atPath: claudeSettingsFile.path) {
            let payload = """
            {
              "allowedMcpServers": []
            }
            """
            try? payload.data(using: .utf8)?.write(to: claudeSettingsFile, options: .atomic)
        }
        if !fm.fileExists(atPath: codexConfigFile.path) {
            let payload = """
            # Generated by Dayflow to isolate Codex CLI from user config
            # Leave empty: no MCP servers or extra features enabled.
            """
            try? payload.data(using: .utf8)?.write(to: codexConfigFile, options: .atomic)
        }

        // Copy auth.json if user has already logged in so CODEX_HOME works.
        let defaultAuth = (NSHomeDirectory() as NSString).appendingPathComponent(".codex/auth.json")
        let sandboxAuth = baseDirectory.appendingPathComponent("auth.json")
        if fm.fileExists(atPath: defaultAuth), !fm.fileExists(atPath: sandboxAuth.path) {
            try? fm.copyItem(atPath: defaultAuth, toPath: sandboxAuth.path)
        }
    }
}

private struct ChatCLIRunResult {
    let exitCode: Int32
    let stdout: String
    let stderr: String
    let startedAt: Date
    let finishedAt: Date
    let usage: TokenUsage?
}

private struct TokenUsage: Sendable {
    let input: Int
    let cachedInput: Int
    let output: Int

    static var zero: TokenUsage { TokenUsage(input: 0, cachedInput: 0, output: 0) }

    func adding(_ other: TokenUsage?) -> TokenUsage {
        guard let other else { return self }
        return TokenUsage(input: input + other.input, cachedInput: cachedInput + other.cachedInput, output: output + other.output)
    }
}

private struct ChatCLIProcessRunner {
    // Extract final assistant text and usage from CLI JSONL so higher layers can parse domain JSON.
    private func parseAssistant(tool: ChatCLITool, raw: String) -> (text: String, usage: TokenUsage?) {
        // Without CLI JSON envelopes, treat stdout as final message.
        let trimmed = raw.trimmingCharacters(in: .whitespacesAndNewlines)
        return (trimmed, nil)
    }

    private func promptWithImageHints(prompt: String, imagePaths: [String]) -> String {
        guard !imagePaths.isEmpty else { return prompt }
        let hints = imagePaths.map { "- " + $0 }.joined(separator: "\n")
        return prompt + "\nImages:\n" + hints
    }
    private static let searchPaths: [String] = {
        let home = NSHomeDirectory()
        return [
            "/usr/local/bin",
            "/opt/homebrew/bin",
            "/usr/bin",
            "/bin",
            "/usr/sbin",
            "/sbin",
            "\(home)/.npm-global/bin",
            "\(home)/.local/bin",
            "\(home)/.cargo/bin",
            "\(home)/.bun/bin",
            "\(home)/.pyenv/bin",
            "\(home)/.pyenv/shims",
            "\(home)/.npm-global/lib/node_modules/@openai/codex/vendor/aarch64-apple-darwin/path",
            "\(home)/.codeium/windsurf/bin",
            "\(home)/.lmstudio/bin"
        ]
    }()

    func run(tool: ChatCLITool, prompt: String, workingDirectory: URL, imagePaths: [String] = [], model: String? = nil, reasoningEffort: String? = nil) throws -> ChatCLIRunResult {
        guard let executable = resolveExecutable(tool: tool) else {
            throw NSError(domain: "ChatCLI", code: -2, userInfo: [NSLocalizedDescriptionKey: "\(tool.rawValue) CLI not found in PATH"])
        }

        var env = ProcessInfo.processInfo.environment
        env["HOME"] = env["HOME"] ?? NSHomeDirectory()
        env["PATH"] = mergedPATH(existing: env["PATH"])
        // Force Codex to use the sandbox config to avoid user MCP servers.
        if tool == .codex {
            env["CODEX_HOME"] = ChatCLIConfigManager.shared.baseDirectory.path
        } else {
            env["CLAUDE_HOME"] = ChatCLIConfigManager.shared.baseDirectory.path
        }

        var args: [String] = []
        switch tool {
        case .codex:
            args = ["exec", "--skip-git-repo-check"]
            if let model = model { args.append(contentsOf: ["-m", model]) }
            if let effort = reasoningEffort { args.append(contentsOf: ["-c", "model_reasoning_effort=\(effort)"]) }
            // Disable MCP per call as belt and suspenders
            args.append(contentsOf: ["-c", "mcp_servers={}", "-c", "experimental_use_rmcp_client=false", "-c", "features.web_search_request=false"])
            for path in imagePaths { args.append(contentsOf: ["--image", path]) }
            // Separator to ensure prompt is not parsed as an option
            args.append("--")
            args.append(prompt)
        case .claude:
            args = ["-p"]
            if let model = model { args.append(contentsOf: ["--model", model]) }
            args.append(contentsOf: ["--dangerously-skip-permissions", "--tools", "Read"])
            // Separator prevents the prompt from being consumed as another tools value
            args.append("--")
            args.append(promptWithImageHints(prompt: prompt, imagePaths: imagePaths))
        }

        let started = Date()
        let process = Process()
        process.executableURL = URL(fileURLWithPath: executable)
        process.arguments = args
        process.currentDirectoryURL = workingDirectory
        process.environment = env

        debugCommand(tool: tool, model: model, executable: executable, args: args, env: env)

        let stdoutPipe = Pipe()
        let stderrPipe = Pipe()
        process.standardOutput = stdoutPipe
        process.standardError = stderrPipe

        try process.run()
        process.waitUntilExit()
        let finished = Date()

        let rawOut = String(data: stdoutPipe.fileHandleForReading.readDataToEndOfFile(), encoding: .utf8) ?? ""
        let stderr = String(data: stderrPipe.fileHandleForReading.readDataToEndOfFile(), encoding: .utf8) ?? ""
        let parsed = parseAssistant(tool: tool, raw: rawOut)
        debugLog(tool: tool, model: model, phase: "run", prompt: prompt, stdout: rawOut, stderr: stderr, usage: parsed.usage)
        return ChatCLIRunResult(exitCode: process.terminationStatus, stdout: parsed.text, stderr: stderr, startedAt: started, finishedAt: finished, usage: parsed.usage)
    }

    private func debugCommand(tool: ChatCLITool, model: String?, executable: String, args: [String], env: [String:String]) {
        let renderedArgs = args.map { $0.contains(" ") ? "\"\($0)\"" : $0 }.joined(separator: " ")
        let header = "[ChatCLI][\(tool.rawValue)][\(model ?? "")] command"
        // Use explicit string concatenation to avoid GRDB SQL interpolation pollution
        let envBits = ["PATH": env["PATH"], "HOME": env["HOME"], "CLLI_CONFIG_HOME": env["CLLI_CONFIG_HOME"]].compactMap { key, value in
            guard let value else { return nil }
            return key + "=" + value
        }.joined(separator: " ")
        print("\(header): \(executable) \(renderedArgs)")
        if !envBits.isEmpty {
            print("\(header) env: \(envBits)")
        }
    }

    private func debugLog(tool: ChatCLITool, model: String?, phase: String, prompt: String, stdout: String, stderr: String, usage: TokenUsage?) {
        func trim(_ s: String, limit: Int = 2000) -> String {
            if s.count > limit { return String(s.prefix(limit)) + "â€¦(truncated)" }
            return s
        }
        let header = "[ChatCLI][\(tool.rawValue)][\(model ?? "")] \(phase)"
        print("\(header) prompt:\n\(trim(prompt))")
        if !stdout.isEmpty { print("\(header) stdout:\n\(trim(stdout))") }
        if !stderr.isEmpty { print("\(header) stderr:\n\(trim(stderr))") }
        if let u = usage {
            print("\(header) usage in=\(u.input) cached=\(u.cachedInput) out=\(u.output)")
        }
    }

    private func mergedPATH(existing: String?) -> String {
        var components: [String] = existing?.split(separator: ":").map { String($0) } ?? []
        for raw in Self.searchPaths {
            let expanded = (raw as NSString).expandingTildeInPath
            if !components.contains(expanded) {
                components.append(expanded)
            }
        }
        return components.joined(separator: ":")
    }

    private func resolveExecutable(tool: ChatCLITool) -> String? {
        let name: String = (tool == .codex) ? "codex" : "claude"
        let fm = FileManager.default
        let paths = mergedPATH(existing: ProcessInfo.processInfo.environment["PATH"]).split(separator: ":").map { String($0) }
        for dir in paths {
            let candidate = (dir as NSString).appendingPathComponent(name)
            if fm.isExecutableFile(atPath: candidate) {
                return candidate
            }
        }
        return nil
    }
}

private struct ChatCLIObservationsEnvelope: Codable {
    struct Item: Codable {
        let start: String
        let end: String
        let text: String
    }
    let observations: [Item]
}

private struct ChatCLICardsEnvelope: Codable {
    struct Item: Codable {
        let start: String?
        let end: String?
        let startTime: String?
        let endTime: String?
        let category: String
        let subcategory: String
        let title: String
        let summary: String
        let detailedSummary: String?
        let distractions: [Distraction]?
        let appSites: AppSites?

        var normalizedStart: String? { start ?? startTime }
        var normalizedEnd: String? { end ?? endTime }
    }
    let cards: [Item]
}

final class ChatCLIProvider: LLMProvider {
    private let tool: ChatCLITool
    private let runner = ChatCLIProcessRunner()
    private let config = ChatCLIConfigManager.shared
    private let frameExtractionInterval: TimeInterval = 60.0

    init(tool: ChatCLITool) {
        self.tool = tool
        config.ensureSandbox()
    }

    // MARK: - Public

    func transcribeVideo(videoData: Data, mimeType: String, prompt: String, batchStartTime: Date, videoDuration: TimeInterval, batchId: Int64?) async throws -> (observations: [Observation], log: LLMCall) {
        let callStart = Date()
        _ = prompt
        _ = mimeType
        // Persist video to a temp file inside sandbox so CLI can see it if tools are enabled.
        let tempVideoURL = config.baseDirectory.appendingPathComponent("\(UUID().uuidString).mp4")
        do {
            try videoData.write(to: tempVideoURL, options: .atomic)
        } catch {
            let finishedAt = Date()
            logFailure(ctx: makeCtx(batchId: batchId, operation: "transcribe", startedAt: callStart), finishedAt: finishedAt, error: error)
            throw error
        }

        defer { try? FileManager.default.removeItem(at: tempVideoURL) }

        var frames: [FrameData] = []
        var usageTotal = TokenUsage.zero
        var sawUsage = false
        // 1) Extract frames
        frames = try extractFrames(from: tempVideoURL, durationHint: videoDuration)
        defer { cleanupFrames(frames) }

        // 2) Per-frame descriptions via CLI
        var frameDescriptions: [(timestamp: TimeInterval, description: String)] = []
        // Batch frames to avoid truncation from Codex mini; chunk to 10
        let batchSize = 10
        for chunk in stride(from: 0, to: frames.count, by: batchSize) {
            let slice = Array(frames[chunk..<min(chunk+batchSize, frames.count)])
            let (initialPairs, initialUsage) = try describeFramesBatch(slice)
            var localPairs = initialPairs
            var localUsage = initialUsage

            // Retry fallback with codex-max if mini returns nothing
            if localPairs.isEmpty && tool == .codex {
                let (retryPairs, retryUsage) = try describeFramesBatch(slice, overrideModel: "gpt-5.1-codex-max", overrideEffort: "high")
                if !retryPairs.isEmpty {
                    localPairs = retryPairs
                    localUsage = retryUsage ?? localUsage
                }
            }

            if let localUsage { usageTotal = usageTotal.adding(localUsage); sawUsage = true }
            for (frame, desc) in localPairs {
                frameDescriptions.append((timestamp: frame.timestamp, description: desc))
            }

            if localPairs.isEmpty {
                logFailure(ctx: makeCtx(batchId: batchId, operation: "describe_frames", startedAt: callStart), finishedAt: Date(), error: NSError(domain: "ChatCLI", code: -99, userInfo: [NSLocalizedDescriptionKey: "Empty frame descriptions for chunk even after fallback"]))
            }
        }

        // 3) Merge descriptions into observations via CLI text prompt
        let (observations, mergeUsage) = try mergeFrameDescriptionsWithCLI(
            frameDescriptions,
            batchStartTime: batchStartTime,
            videoDuration: videoDuration,
            batchId: batchId,
            callStart: callStart
        )

        if let mergeUsage { usageTotal = usageTotal.adding(mergeUsage); sawUsage = true }

        cleanupFrames(frames)

        let finishedAt = Date()
        let headers = sawUsage ? tokenHeaders(from: usageTotal) : nil
        logSuccess(ctx: makeCtx(batchId: batchId, operation: "transcribe", startedAt: callStart), finishedAt: finishedAt, stdout: "frames:\(frames.count) obs:\(observations.count)", stderr: "", responseHeaders: headers)

        let llmCall = makeLLMCall(start: callStart, end: finishedAt, input: "frames \(frames.count)", output: "obs \(observations.count)")
        return (observations, llmCall)
    }

    func generateActivityCards(observations: [Observation], context: ActivityGenerationContext, batchId: Int64?) async throws -> (cards: [ActivityCardData], log: LLMCall) {
        enum CardParseError: LocalizedError {
            case empty(rawOutput: String)
            case decodeFailure(rawOutput: String)
            case validationFailed(details: String, rawOutput: String)

            var errorDescription: String? {
                switch self {
                case .empty(let rawOutput):
                    return "No cards returned.\n\nðŸ“„ RAW OUTPUT:\n" + rawOutput
                case .decodeFailure(let rawOutput):
                    return "Failed to decode cards.\n\nðŸ“„ RAW OUTPUT:\n" + rawOutput
                case .validationFailed(let details, let rawOutput):
                    return details + "\n\nðŸ“„ RAW OUTPUT:\n" + rawOutput
                }
            }
        }

        let callStart = Date()
        let basePrompt = buildCardsPrompt(observations: observations, context: context)
        var actualPromptUsed = basePrompt

        let model: String
        let effort: String?
        switch tool {
        case .claude:
            model = "sonnet"
            effort = nil
        case .codex:
            model = "gpt-5.1-codex-max"
            effort = "high"
        }

        var lastError: Error?
        var lastRun: ChatCLIRunResult?
        var lastRawOutput: String = ""
        var parsedCards: [ActivityCardData] = []

        for attempt in 1...4 {
            do {
                let run = try runner.run(tool: tool, prompt: actualPromptUsed, workingDirectory: config.baseDirectory, model: model, reasoningEffort: effort)
                lastRun = run
                lastRawOutput = run.stdout
                let cards = try parseCards(from: run.stdout)
                guard !cards.isEmpty else { throw CardParseError.empty(rawOutput: run.stdout) }

                let normalizedCards = normalizeCards(cards, descriptors: context.categories)
                let (coverageValid, coverageError) = validateTimeCoverage(existingCards: context.existingCards, newCards: normalizedCards)
                let (durationValid, durationError) = validateTimeline(normalizedCards)

                if coverageValid && durationValid {
                    parsedCards = normalizedCards
                    let finishedAt = run.finishedAt
                    logSuccess(ctx: makeCtx(batchId: batchId, operation: "generate_cards", startedAt: callStart), finishedAt: finishedAt, stdout: run.stdout, stderr: run.stderr, responseHeaders: tokenHeaders(from: run.usage))
                    let llmCall = makeLLMCall(start: callStart, end: finishedAt, input: actualPromptUsed, output: run.stdout)
                    return (parsedCards, llmCall)
                }

                // Validation failed - prepare retry with error feedback
                var errorMessages: [String] = []
                if !coverageValid, let coverageError { errorMessages.append(coverageError) }
                if !durationValid, let durationError { errorMessages.append(durationError) }
                let combinedError = errorMessages.joined(separator: "\n\n")
                lastError = CardParseError.validationFailed(details: combinedError, rawOutput: run.stdout)
                actualPromptUsed = basePrompt + "\n\nPREVIOUS ATTEMPT FAILED - CRITICAL REQUIREMENTS NOT MET:\n\n" + combinedError + "\n\nPlease fix these issues and ensure your output meets all requirements."
                print("[ChatCLI] generate_cards validation failed (attempt " + String(attempt) + "): " + combinedError)
            } catch {
                lastError = error
                print("[ChatCLI] generate_cards attempt " + String(attempt) + " failed: " + error.localizedDescription + " â€” retrying")
                actualPromptUsed = basePrompt
            }
        }

        let finishedAt = lastRun?.finishedAt ?? Date()
        let finalError = lastError ?? CardParseError.decodeFailure(rawOutput: lastRawOutput)
        logFailure(ctx: makeCtx(batchId: batchId, operation: "generate_cards", startedAt: callStart), finishedAt: finishedAt, error: finalError)
        throw finalError
    }

    // MARK: - Prompt builders

    private func buildCardsPrompt(observations: [Observation], context: ActivityGenerationContext) -> String {
        // Use explicit string concatenation to avoid GRDB SQL interpolation pollution
        let transcriptText = observations.map { obs in
            let startTime = formatTimestampForPrompt(obs.startTs)
            let endTime = formatTimestampForPrompt(obs.endTs)
            return "[" + startTime + " - " + endTime + "]: " + obs.observation
        }.joined(separator: "\n")

        let encoder = JSONEncoder()
        encoder.outputFormatting = .prettyPrinted
        let existingCardsData = try? encoder.encode(context.existingCards)
        let existingCardsJSON = existingCardsData.flatMap { String(data: $0, encoding: .utf8) } ?? "[]"
        let promptSections = GeminiPromptSections(overrides: GeminiPromptPreferences.load())

        // Build prompt with explicit concatenation to avoid GRDB SQL interpolation pollution
        let categoriesSectionText = categoriesSection(from: context.categories)

        return """
        You are synthesizing a user's activity log into timeline cards. Each card represents one main thing they did.

        CORE PRINCIPLE:
        Each card = one coherent activity. Time is a constraint (10-60 min), not a goal. Don't stuff unrelated activities into one card just to fill time.

        SPLITTING RULES:
        - Minimum card length: 10 minutes
        - Maximum card length: 60 minutes
        - If an activity clearly shifts focus, start a new card (even if current card is short)
        - If you need "and" to connect two unrelated activities in a title, that's two cards
        - Brief interruptions (<5 min) that don't change your focus = distractions within the card
        - Sustained different activities (>10 min) = new card, not a distraction

        CONTINUITY RULE:
        Never introduce gaps or overlaps. Adjacent cards should meet cleanly. Preserve any original gaps from the source timeline.

        """ + promptSections.title + """


        """ + promptSections.summary + """


        """ + promptSections.detailedSummary + """


        DISTRACTIONS

        A distraction is a brief (<5 min) unrelated interruption that doesn't change the card's main focus.

        NOT distractions:
        - A 24-minute League game (that's its own card)
        - A 10-minute Twitter scroll (new card or merge thoughtfully)
        - Sub-tasks related to the main activity

        """ + categoriesSectionText + """


        APP SITES

        Identify primary and secondary apps/sites used.

        Rules:
        - primary: main app for the card
        - secondary: another meaningful app OR the enclosing app (browser) if relevant
        - Use canonical domains: figma.com, notion.so, docs.google.com, x.com, mail.google.com
        - Be specific: docs.google.com not google.com

        DECISION PROCESS

        Before finalizing a card, ask:
        1. What's the one main thing in this card?
        2. Can I title it without using "and" between unrelated things?
        3. Are there any sustained (>10 min) activities that should be their own card?
        4. Are the "distractions" actually brief interruptions, or separate activities?

        INPUTS:
        Previous cards: \(existingCardsJSON)
        New observations: \(transcriptText)

        OUTPUT:
        Return ONLY a raw JSON array. No code fences, no markdown, no commentary.

        [
          {
            "startTime": "1:12 AM",
            "endTime": "1:30 AM",
            "category": "",
            "subcategory": "",
            "title": "",
            "summary": "",
            "detailedSummary": "",
            "distractions": [
              {
                "startTime": "1:15 AM",
                "endTime": "1:18 AM",
                "title": "",
                "summary": ""
              }
            ],
            "appSites": {
              "primary": "",
              "secondary": ""
            }
          }
        ]
        """
    }

    // MARK: - Parsing

    private func parseObservations(from output: String, batchId: Int64?, batchStartTime: Date) -> [Observation] {
        guard let data = output.data(using: .utf8),
              let envelope = try? JSONDecoder().decode(ChatCLIObservationsEnvelope.self, from: data) else {
            return []
        }
        return envelope.observations.compactMap { item in
            let startSeconds = TimeInterval(parseVideoTimestamp(item.start))
            let endSeconds = TimeInterval(parseVideoTimestamp(item.end))
            guard endSeconds > startSeconds else { return nil }

            let startDate = batchStartTime.addingTimeInterval(startSeconds)
            let endDate = batchStartTime.addingTimeInterval(endSeconds)

            let startEpoch = Int(startDate.timeIntervalSince1970)
            let endEpoch = max(startEpoch + 1, Int(endDate.timeIntervalSince1970))

            return Observation(
                id: nil,
                batchId: batchId ?? -1,
                startTs: startEpoch,
                endTs: endEpoch,
                observation: item.text,
                metadata: nil,
                llmModel: tool.rawValue,
                createdAt: Date()
            )
        }
    }

    private func parseCards(from output: String) throws -> [ActivityCardData] {
        guard let data = output.data(using: .utf8) else {
            throw NSError(domain: "ChatCLI", code: -31, userInfo: [NSLocalizedDescriptionKey: "No stdout to parse"])
        }

        let decoder = JSONDecoder()

        // Strategy 1: {"cards":[...]}
        if let envelope = try? decoder.decode(ChatCLICardsEnvelope.self, from: data) {
            let cards: [ActivityCardData?] = envelope.cards.map { item in
                guard let start = item.normalizedStart, let end = item.normalizedEnd else { return nil }
                return ActivityCardData(
                    startTime: start,
                    endTime: end,
                    category: item.category,
                    subcategory: item.subcategory,
                    title: item.title,
                    summary: item.summary,
                    detailedSummary: item.detailedSummary ?? item.summary,
                    distractions: item.distractions,
                    appSites: item.appSites
                )
            }
            let filtered = cards.compactMap { $0 }
            if !filtered.isEmpty { return filtered }
        }

        // Strategy 2: top-level array of cards (Gemini-style)
        if let arrayCards = try? decoder.decode([ActivityCardData].self, from: data) {
            return arrayCards
        }

        // Strategy 3: Claude often wraps valid JSON in code fences or adds prefix/suffix text.
        // As a last resort, grab the substring between the first '[' and the last ']' and try again.
        if let firstBracket = output.firstIndex(of: "["),
           let lastBracket = output.lastIndex(of: "]"),
           firstBracket < lastBracket {
            let sliced = String(output[firstBracket...lastBracket])
                .replacingOccurrences(of: "```json", with: "")
                .replacingOccurrences(of: "```", with: "")
                .trimmingCharacters(in: .whitespacesAndNewlines)

            if let slicedData = sliced.data(using: .utf8) {
                if let envelope = try? decoder.decode(ChatCLICardsEnvelope.self, from: slicedData) {
                    let cards: [ActivityCardData?] = envelope.cards.map { item in
                        guard let start = item.normalizedStart, let end = item.normalizedEnd else { return nil }
                        return ActivityCardData(
                            startTime: start,
                            endTime: end,
                            category: item.category,
                            subcategory: item.subcategory,
                            title: item.title,
                            summary: item.summary,
                            detailedSummary: item.detailedSummary ?? item.summary,
                            distractions: item.distractions,
                            appSites: item.appSites
                        )
                    }
                    let filtered = cards.compactMap { $0 }
                    if !filtered.isEmpty { return filtered }
                }

                if let arrayCards = try? decoder.decode([ActivityCardData].self, from: slicedData) {
                    return arrayCards
                }
            }
        }

        throw NSError(domain: "ChatCLI", code: -32, userInfo: [NSLocalizedDescriptionKey: "Failed to decode activity cards"])
    }

    // MARK: - Frame processing and merging

    private struct FrameData {
        let timestamp: TimeInterval
        let path: String
    }

    private struct FrameDescriptionResponse: Codable {
        let description: String
    }

    private struct FrameDescriptionsEnvelope: Codable {
        struct Item: Codable { let index: Int; let description: String }
        let frames: [Item]
    }

    private struct SegmentMergeResponse: Codable {
        struct Segment: Codable {
            let start: String
            let end: String
            let description: String
        }
        let segments: [Segment]
    }

    private func extractFrames(from videoURL: URL, durationHint: TimeInterval) throws -> [FrameData] {
        let asset = AVAsset(url: videoURL)
        let duration = CMTimeGetSeconds(asset.duration)
        let total = duration > 0 ? duration : max(1, durationHint)

        let generator = AVAssetImageGenerator(asset: asset)
        generator.requestedTimeToleranceBefore = .zero
        generator.requestedTimeToleranceAfter = .zero
        generator.appliesPreferredTrackTransform = true
        // Keep the smallest side at most 600px to accommodate ultrawide without over-downscaling.
        if let track = asset.tracks(withMediaType: .video).first {
            let size = track.naturalSize.applying(track.preferredTransform)
            let w = abs(size.width)
            let h = abs(size.height)
            if w >= h {
                generator.maximumSize = CGSize(width: 6000, height: 600) // landscape: cap height to 600
            } else {
                generator.maximumSize = CGSize(width: 600, height: 6000) // portrait: cap width to 600
            }
        } else {
            generator.maximumSize = CGSize(width: 600, height: 600)
        }

        var frames: [FrameData] = []
        var t: TimeInterval = 0

        while t <= total {
            let cm = CMTime(seconds: t, preferredTimescale: 600)
            if let cg = try? generator.copyCGImage(at: cm, actualTime: nil),
               let path = try? writeImage(cgImage: cg) {
                frames.append(FrameData(timestamp: t, path: path))
            }
            t += frameExtractionInterval
        }

        // Ensure last frame
        if let cg = try? generator.copyCGImage(at: CMTime(seconds: total, preferredTimescale: 600), actualTime: nil),
           let path = try? writeImage(cgImage: cg) {
            if !frames.contains(where: { abs($0.timestamp - total) < 1.0 }) {
                frames.append(FrameData(timestamp: total, path: path))
            }
        }
        return frames
    }

    private func describeFramesBatch(_ frames: [FrameData], overrideModel: String? = nil, overrideEffort: String? = nil) throws -> ([(FrameData, String)], TokenUsage?) {
        guard !frames.isEmpty else { return ([], nil) }

        let prompt = """
        You will see multiple computer screen snapshots attached in the order provided.
        Describe what you see on this computer screen in 1-2 sentences.
        Focus on: what application/site is open, what the user is doing, and any relevant details visible.
        Be specific and factual.
        
        GOOD EXAMPLES:
        âœ“ "VS Code open with index.js file, writing a React component for user authentication."
        âœ“ "Gmail compose window writing email to client@company.com about project timeline."
        âœ“ "Slack conversation in #engineering channel discussing API rate limiting issues."
        
        BAD EXAMPLES:
        âœ— "User is coding" (too vague)
        âœ— "Looking at a website" (doesn't identify which site)
        âœ— "Working on computer" (completely non-specific)
        Reply ONLY with JSON: {"frames":[{"index":1,"description":"<one sentence about the visible activity/app/site>"}]}.
        Include one entry per image in the same order (1 = first image you received). No prose, no extra keys.
        
        """

        let model: String
        let effort: String?
        if let overrideModel {
            model = overrideModel
            effort = overrideEffort
        } else {
            switch tool {
            case .claude:
                model = "haiku"
                effort = nil
            case .codex:
                model = "gpt-5.1-codex-mini"
                effort = "high"
            }
        }

        let run = try runner.run(tool: tool, prompt: prompt, workingDirectory: config.baseDirectory, imagePaths: frames.map { $0.path }, model: model, reasoningEffort: effort)
        guard run.exitCode == 0 else { return ([], run.usage) }

        // Try strict JSON decode first
        if let data = run.stdout.data(using: .utf8),
           let parsed = try? JSONDecoder().decode(FrameDescriptionsEnvelope.self, from: data),
           !parsed.frames.isEmpty {
            var results: [(FrameData, String)] = []
            for (idx, frame) in frames.enumerated() {
                if let match = parsed.frames.first(where: { $0.index == idx + 1 }) {
                    let desc = match.description.trimmingCharacters(in: .whitespacesAndNewlines)
                    if !desc.isEmpty { results.append((frame, desc)) }
                }
            }
            if !results.isEmpty { return (results, run.usage) }
        }

        // Fallback: try to strip code fences and decode again
        let stripped = run.stdout.replacingOccurrences(of: "```json", with: "").replacingOccurrences(of: "```", with: "")
        if let data = stripped.data(using: .utf8),
           let parsed = try? JSONDecoder().decode(FrameDescriptionsEnvelope.self, from: data),
           !parsed.frames.isEmpty {
            var results: [(FrameData, String)] = []
            for (idx, frame) in frames.enumerated() {
                if let match = parsed.frames.first(where: { $0.index == idx + 1 }) {
                    let desc = match.description.trimmingCharacters(in: .whitespacesAndNewlines)
                    if !desc.isEmpty { results.append((frame, desc)) }
                }
            }
            if !results.isEmpty { return (results, run.usage) }
        }

        // Last resort: split lines -> descriptions by order
        var results: [(FrameData, String)] = []
        let lines = run.stdout.split(whereSeparator: { $0.isNewline })
        for (idx, frame) in frames.enumerated() {
            if idx < lines.count {
                let desc = String(lines[idx]).trimmingCharacters(in: .whitespacesAndNewlines)
                if !desc.isEmpty { results.append((frame, desc)) }
            }
        }
        return (results, run.usage)
    }

    private func mergeFrameDescriptionsWithCLI(_ frames: [(timestamp: TimeInterval, description: String)],
                                               batchStartTime: Date,
                                               videoDuration: TimeInterval,
                                               batchId: Int64?,
                                               callStart: Date) throws -> ([Observation], TokenUsage?) {
        guard !frames.isEmpty else { return ([], nil) }

        let durationString = formatSeconds(videoDuration)
        let lines = frames.map { "- " + formatSeconds($0.timestamp) + ": " + $0.description }.joined(separator: "\n")
        let prompt = "You are given timestamped screen descriptions from a video (" + durationString + ").\n" +
            "Produce 2-5 segments that cover the video. Respond ONLY with JSON:\n" +
            "{\"segments\":[{\"start\":\"HH:MM:SS\",\"end\":\"HH:MM:SS\",\"description\":\"...\"}]}\n" +
            "Rules:\n" +
            "- Segments must be in order, non-overlapping, within 00:00:00-" + durationString + ".\n" +
            "- Cover at least 80% of the timeline; merge short gaps.\n" +
            "- No text outside the JSON.\n" +
            "Snapshots:\n" + lines

        let model: String
        let effort: String?
        switch tool {
        case .claude:
            model = "sonnet"
            effort = nil // Claude CLI doesn't expose thinking flag; prompt handles brevity
        case .codex:
            model = "gpt-5.1-codex-max"
            effort = "high"
        }

        let run = try runner.run(tool: tool, prompt: prompt, workingDirectory: config.baseDirectory, model: model, reasoningEffort: effort)
        guard run.exitCode == 0,
              let data = run.stdout.data(using: .utf8),
              let parsed = try? JSONDecoder().decode(SegmentMergeResponse.self, from: data),
              !parsed.segments.isEmpty else {
            return (fallbackObservations(frames: frames, batchId: batchId, batchStartTime: batchStartTime, videoDuration: videoDuration), run.usage)
        }

        var observations: [Observation] = []
        for seg in parsed.segments.prefix(5) {
            let startSeconds = TimeInterval(parseVideoTimestamp(seg.start))
            let endSeconds = TimeInterval(parseVideoTimestamp(seg.end))
            guard endSeconds > startSeconds else { continue }

            let clampedEndSeconds = videoDuration > 0 ? min(endSeconds, videoDuration) : endSeconds
            let startDate = batchStartTime.addingTimeInterval(startSeconds)
            let endDate = batchStartTime.addingTimeInterval(clampedEndSeconds)

            let startEpoch = Int(startDate.timeIntervalSince1970)
            let endEpoch = max(startEpoch + 1, Int(endDate.timeIntervalSince1970))
            observations.append(
                Observation(
                    id: nil,
                    batchId: batchId ?? -1,
                    startTs: startEpoch,
                    endTs: endEpoch,
                    observation: seg.description,
                    metadata: nil,
                    llmModel: tool.rawValue,
                    createdAt: Date()
                )
            )
        }

        if observations.isEmpty {
            return (fallbackObservations(frames: frames, batchId: batchId, batchStartTime: batchStartTime, videoDuration: videoDuration), run.usage)
        }
        return (observations, run.usage)
    }

    private func fallbackObservations(frames: [(timestamp: TimeInterval, description: String)],
                                      batchId: Int64?,
                                      batchStartTime: Date,
                                      videoDuration: TimeInterval) -> [Observation] {
        let sorted = frames.sorted { $0.timestamp < $1.timestamp }
        var result: [Observation] = []
        for item in sorted.prefix(5) {
            let startSeconds = max(0.0, item.timestamp)
            let endSeconds = startSeconds + frameExtractionInterval
            let clampedEndSeconds = videoDuration > 0 ? min(videoDuration, endSeconds) : endSeconds

            let startDate = batchStartTime.addingTimeInterval(startSeconds)
            let endDate = batchStartTime.addingTimeInterval(max(clampedEndSeconds, startSeconds + 1))

            let startEpoch = Int(startDate.timeIntervalSince1970)
            let endEpoch = max(startEpoch + 1, Int(endDate.timeIntervalSince1970))
            result.append(
                Observation(
                    id: nil,
                    batchId: batchId ?? -1,
                    startTs: startEpoch,
                    endTs: endEpoch,
                    observation: item.description,
                    metadata: nil,
                    llmModel: tool.rawValue,
                    createdAt: Date()
                )
            )
        }
        return result
    }

    private func writeImage(cgImage: CGImage) throws -> String {
        let rep = NSBitmapImageRep(cgImage: cgImage)
        guard let data = rep.representation(using: .jpeg, properties: [.compressionFactor: 0.85]) else {
            throw NSError(domain: "ChatCLIProvider", code: -11, userInfo: [NSLocalizedDescriptionKey: "Failed to encode frame"])
        }
        let dir = config.baseDirectory.appendingPathComponent("frames", isDirectory: true)
        if !FileManager.default.fileExists(atPath: dir.path) {
            try FileManager.default.createDirectory(at: dir, withIntermediateDirectories: true)
        }
        let path = dir.appendingPathComponent("\(UUID().uuidString).jpg")
        try data.write(to: path, options: .atomic)
        return path.path
    }

    private func formatSeconds(_ seconds: TimeInterval) -> String {
        let s = Int(seconds.rounded())
        let h = s / 3600
        let m = (s % 3600) / 60
        let sec = s % 60
        return String(format: "%02d:%02d:%02d", h, m, sec)
    }

    private func cleanupFrames(_ frames: [FrameData]) {
        let fm = FileManager.default
        for frame in frames {
            try? fm.removeItem(atPath: frame.path)
        }
    }

    private func categoriesSection(from descriptors: [LLMCategoryDescriptor]) -> String {
        guard !descriptors.isEmpty else {
            return "USER CATEGORIES: No categories configured. Use consistent labels based on the activity story."
        }

        // Use explicit string concatenation to avoid GRDB SQL interpolation pollution
        let allowed = descriptors.map { "\"" + $0.name + "\"" }.joined(separator: ", ")
        var lines: [String] = ["USER CATEGORIES (choose exactly one label):"]

        for (index, descriptor) in descriptors.enumerated() {
            var desc = descriptor.description?.trimmingCharacters(in: .whitespacesAndNewlines) ?? ""
            if descriptor.isIdle && desc.isEmpty {
                desc = "Use when the user is idle for most of this period."
            }
            let suffix = desc.isEmpty ? "" : " â€” " + desc
            lines.append(String(index + 1) + ". \"" + descriptor.name + "\"" + suffix)
        }

        if let idle = descriptors.first(where: { $0.isIdle }) {
            lines.append("Only use \"" + idle.name + "\" when the user is idle for more than half of the timeframe. Otherwise pick the closest non-idle label.")
        }

        lines.append("Return the category exactly as written. Allowed values: [" + allowed + "].")
        return lines.joined(separator: "\n")
    }

    private func normalizeCategory(_ raw: String, descriptors: [LLMCategoryDescriptor]) -> String {
        let cleaned = raw.trimmingCharacters(in: .whitespacesAndNewlines)
        guard !cleaned.isEmpty else { return descriptors.first?.name ?? "" }
        let normalized = cleaned.lowercased()
        if let match = descriptors.first(where: { $0.name.trimmingCharacters(in: .whitespacesAndNewlines).lowercased() == normalized }) {
            return match.name
        }
        if let idle = descriptors.first(where: { $0.isIdle }) {
            let idleLabels = ["idle", "idle time", idle.name.lowercased()]
            if idleLabels.contains(normalized) {
                return idle.name
            }
        }
        return descriptors.first?.name ?? cleaned
    }

    private func normalizeCards(_ cards: [ActivityCardData], descriptors: [LLMCategoryDescriptor]) -> [ActivityCardData] {
        cards.map { card in
            ActivityCardData(
                startTime: card.startTime,
                endTime: card.endTime,
                category: normalizeCategory(card.category, descriptors: descriptors),
                subcategory: card.subcategory,
                title: card.title,
                summary: card.summary,
                detailedSummary: card.detailedSummary,
                distractions: card.distractions,
                appSites: card.appSites
            )
        }
    }

    private struct TimeRange { let start: Double; let end: Double }

    private func timeToMinutes(_ timeStr: String) -> Double {
        let trimmed = timeStr.trimmingCharacters(in: .whitespacesAndNewlines)
        if trimmed.contains("AM") || trimmed.contains("PM") {
            let formatter = DateFormatter()
            formatter.dateFormat = "h:mm a"
            formatter.locale = Locale(identifier: "en_US_POSIX")
            guard let date = formatter.date(from: trimmed) else { return 0 }
            let components = Calendar.current.dateComponents([.hour, .minute], from: date)
            let hours = Double(components.hour ?? 0)
            let minutes = Double(components.minute ?? 0)
            return hours * 60 + minutes
        } else {
            let seconds = parseVideoTimestamp(timeStr)
            return Double(seconds) / 60.0
        }
    }

    private func mergeOverlappingRanges(_ ranges: [TimeRange]) -> [TimeRange] {
        guard !ranges.isEmpty else { return [] }
        let sorted = ranges.sorted { $0.start < $1.start }
        var merged: [TimeRange] = []
        for range in sorted {
            if merged.isEmpty || range.start > merged.last!.end + 1 {
                merged.append(range)
            } else {
                let last = merged.removeLast()
                merged.append(TimeRange(start: last.start, end: max(last.end, range.end)))
            }
        }
        return merged
    }

    private func validateTimeCoverage(existingCards: [ActivityCardData], newCards: [ActivityCardData]) -> (isValid: Bool, error: String?) {
        guard !existingCards.isEmpty else { return (true, nil) }

        var inputRanges: [TimeRange] = []
        for card in existingCards {
            let startMin = timeToMinutes(card.startTime)
            var endMin = timeToMinutes(card.endTime)
            if endMin < startMin { endMin += 24 * 60 }
            inputRanges.append(TimeRange(start: startMin, end: endMin))
        }
        let mergedInputRanges = mergeOverlappingRanges(inputRanges)

        var outputRanges: [TimeRange] = []
        for card in newCards {
            let startMin = timeToMinutes(card.startTime)
            var endMin = timeToMinutes(card.endTime)
            if endMin < startMin { endMin += 24 * 60 }
            guard endMin - startMin >= 0.1 else { continue }
            outputRanges.append(TimeRange(start: startMin, end: endMin))
        }

        let flexibility = 3.0 // minutes
        var uncoveredSegments: [(start: Double, end: Double)] = []

        for inputRange in mergedInputRanges {
            var coveredStart = inputRange.start
            var safetyCounter = 10000
            while coveredStart < inputRange.end && safetyCounter > 0 {
                safetyCounter -= 1
                var foundCoverage = false
                for outputRange in outputRanges {
                    if outputRange.start - flexibility <= coveredStart && coveredStart <= outputRange.end + flexibility {
                        let newCoveredStart = outputRange.end
                        coveredStart = max(coveredStart + 0.01, newCoveredStart)
                        foundCoverage = true
                        break
                    }
                }

                if !foundCoverage {
                    var nextCovered = inputRange.end
                    for outputRange in outputRanges {
                        if outputRange.start > coveredStart && outputRange.start < nextCovered {
                            nextCovered = outputRange.start
                        }
                    }
                    if nextCovered > coveredStart {
                        uncoveredSegments.append((start: coveredStart, end: min(nextCovered, inputRange.end)))
                        coveredStart = nextCovered
                    } else {
                        uncoveredSegments.append((start: coveredStart, end: inputRange.end))
                        break
                    }
                }
            }
            if safetyCounter == 0 {
                return (false, "Time coverage validation loop exceeded safety limit - possible infinite loop detected")
            }
        }

        if !uncoveredSegments.isEmpty {
            var uncoveredDesc: [String] = []
            for segment in uncoveredSegments {
                let duration = segment.end - segment.start
                if duration > flexibility {
                    let startTime = minutesToTimeString(segment.start)
                    let endTime = minutesToTimeString(segment.end)
                    uncoveredDesc.append(startTime + "-" + endTime + " (" + String(Int(duration)) + " min)")
                }
            }

            if !uncoveredDesc.isEmpty {
                let missing = uncoveredDesc.joined(separator: ", ")
                var errorMsg = "Missing coverage for time segments: " + missing
                errorMsg += "\n\nðŸ“¥ INPUT CARDS:"
                for (i, card) in existingCards.enumerated() {
                    errorMsg += "\n  " + String(i + 1) + ". " + card.startTime + " - " + card.endTime + ": " + card.title
                }
                errorMsg += "\n\nðŸ“¤ OUTPUT CARDS:"
                for (i, card) in newCards.enumerated() {
                    errorMsg += "\n  " + String(i + 1) + ". " + card.startTime + " - " + card.endTime + ": " + card.title
                }
                return (false, errorMsg)
            }
        }

        return (true, nil)
    }

    private func validateTimeline(_ cards: [ActivityCardData]) -> (isValid: Bool, error: String?) {
        for (index, card) in cards.enumerated() {
            let startTime = card.startTime
            let endTime = card.endTime
            var durationMinutes: Double = 0

            if startTime.contains("AM") || startTime.contains("PM") {
                let formatter = DateFormatter()
                formatter.dateFormat = "h:mm a"
                formatter.locale = Locale(identifier: "en_US_POSIX")

                if let startDate = formatter.date(from: startTime),
                   let endDate = formatter.date(from: endTime) {
                    var adjustedEndDate = endDate
                    if endDate < startDate {
                        adjustedEndDate = Calendar.current.date(byAdding: .day, value: 1, to: endDate) ?? endDate
                    }
                    durationMinutes = adjustedEndDate.timeIntervalSince(startDate) / 60.0
                } else {
                    durationMinutes = 0
                }
            } else {
                let startSeconds = parseVideoTimestamp(startTime)
                let endSeconds = parseVideoTimestamp(endTime)
                durationMinutes = Double(endSeconds - startSeconds) / 60.0
            }

            if durationMinutes < 10 && index < cards.count - 1 {
                let msg = String(format: "Card %d '%@' is only %.1f minutes long", index + 1, card.title, durationMinutes)
                return (false, msg)
            }
        }

        return (true, nil)
    }

    private func minutesToTimeString(_ minutes: Double) -> String {
        let hours = (Int(minutes) / 60) % 24
        let mins = Int(minutes) % 60
        let period = hours < 12 ? "AM" : "PM"
        var displayHour = hours % 12
        if displayHour == 0 { displayHour = 12 }
        return String(format: "%d:%02d %@", displayHour, mins, period)
    }

    // MARK: - Logging helpers

    private func makeCtx(batchId: Int64?, operation: String, startedAt: Date) -> LLMCallContext {
        LLMCallContext(
            batchId: batchId,
            callGroupId: nil,
            attempt: 1,
            provider: "chat_cli",
            model: tool.rawValue,
            operation: operation,
            requestMethod: nil,
            requestURL: nil,
            requestHeaders: nil,
            requestBody: nil,
            startedAt: startedAt
        )
    }

    private func tokenHeaders(from usage: TokenUsage?) -> [String:String]? {
        guard let usage else { return nil }
        return [
            "x-usage-input": String(usage.input),
            "x-usage-cached-input": String(usage.cachedInput),
            "x-usage-output": String(usage.output)
        ]
    }

    private func logSuccess(ctx: LLMCallContext, finishedAt: Date, stdout: String, stderr: String, responseHeaders: [String:String]? = nil) {
        let http = LLMHTTPInfo(httpStatus: nil, responseHeaders: responseHeaders, responseBody: stdout.data(using: .utf8))
        LLMLogger.logSuccess(ctx: ctx, http: http, finishedAt: finishedAt)
    }

    private func logFailure(ctx: LLMCallContext, finishedAt: Date, error: Error) {
        LLMLogger.logFailure(ctx: ctx, http: nil, finishedAt: finishedAt, errorDomain: "ChatCLI", errorCode: (error as NSError).code, errorMessage: error.localizedDescription)
    }

    private func makeLLMCall(start: Date, end: Date, input: String?, output: String?) -> LLMCall {
        LLMCall(timestamp: end, latency: end.timeIntervalSince(start), input: input, output: output)
    }
}
